{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b496da",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/state-reducers.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239428-lesson-2-state-reducers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae0ff7-497d-4c31-a57a-00fe92799232",
   "metadata": {},
   "source": [
    "# State Reducers \n",
    "\n",
    "## Review\n",
    "\n",
    "We covered a few different ways to define LangGraph state schema, including `TypedDict`, `Pydantic`, or `Dataclasses`.\n",
    " \n",
    "## Goals\n",
    "\n",
    "Now, we're going to dive into reducers, which specify how state updates are performed on specific keys / channels in the state schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398c5e8e-641f-4be6-b1e8-7531f86bd2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bd534-c5be-48fe-91bc-af39ebee76b7",
   "metadata": {},
   "source": [
    "## Default overwriting state\n",
    "\n",
    "Let's use a `TypedDict` as our state schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e2438c-9353-4256-bc3c-1bb830374c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69634df1-4f02-446f-b5cf-6a83d1e15e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\" : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a099c-c41c-412f-8f05-e7436388ae79",
   "metadata": {},
   "source": [
    "Let's look at the state update, `return {\"foo\": state['foo'] + 1}`.\n",
    "\n",
    "As discussed before, by default LangGraph doesn't know the preferred way to update the state.\n",
    " \n",
    "So, it will just overwrite the value of `foo` in `node_1`: \n",
    "\n",
    "```\n",
    "return {\"foo\": state['foo'] + 1}\n",
    "```\n",
    " \n",
    "If we pass `{'foo': 1}` as input, the state returned from the graph is `{'foo': 2}`.\n",
    "\n",
    "## Branching\n",
    "\n",
    "Let's look at a case where our nodes branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8d6ad4-2991-4325-933d-67057bc150f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    foo: int\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_1\", \"node_3\")\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106729b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n",
      "---Node 3---\n",
      "InvalidUpdateError occurred: At key 'foo': Can receive only one value per step. Use an Annotated key to handle multiple values.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE\n"
     ]
    }
   ],
   "source": [
    "from langgraph.errors import InvalidUpdateError\n",
    "try:\n",
    "    graph.invoke({\"foo\" : 1})\n",
    "except InvalidUpdateError as e:\n",
    "    print(f\"InvalidUpdateError occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9717ccd-3d34-476a-8952-e6a7629ebefe",
   "metadata": {},
   "source": [
    "We see a problem! \n",
    "\n",
    "Node 1 branches to nodes 2 and 3.\n",
    "\n",
    "Nodes 2 and 3 run in parallel, which means they run in the same step of the graph.\n",
    "\n",
    "They both attempt to overwrite the state *within the same step*. \n",
    "\n",
    "This is ambiguous for the graph! Which state should it keep? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1609cf7-dc47-4926-a154-77904b6cc550",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "[Reducers](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) give us a general way to address this problem.\n",
    "\n",
    "They specify how to perform updates.\n",
    "\n",
    "We can use the `Annotated` type to specify a reducer function. \n",
    "\n",
    "For example, in this case let's append the value returned from each node rather than overwriting them.\n",
    "\n",
    "We just need a reducer that can perform this: `operator.add` is a function from Python's built-in operator module.\n",
    "\n",
    "When `operator.add` is applied to lists, it performs list concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103d808c-55ec-44f2-a688-7b5e1572875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: Annotated[list[int], add]\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [state['foo'][0] + 1]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e68cdff-f6e1-4de5-a7bf-6ca0cfee19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': [1, 2]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\" : [1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbd6e0-0207-4049-b86d-c006cbba630b",
   "metadata": {},
   "source": [
    "Now, our state key `foo` is a list.\n",
    "\n",
    "This `operator.add` reducer function will append updates from each node to this list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "768fd0ed-5e24-44a4-b14d-0e299310e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_1\", \"node_3\")\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439baad-5a75-4188-b936-dbe74cdd9078",
   "metadata": {},
   "source": [
    "We can see that updates in nodes 2 and 3 are performed concurrently because they are in the same step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44598f97-0a59-4ed4-9d9a-e15a98b3d8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': [1, 2, 3, 3]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\" : [1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87faaa07-2955-4466-9bca-4b536e05f260",
   "metadata": {},
   "source": [
    "Now, let's see what happens if we pass `None` to `foo`.\n",
    "\n",
    "We see an error because our reducer, `operator.add`, attempts to concatenate `NoneType` pass as input to list in `node_1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f05984b-2bc7-48d1-b070-c8a001a6b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError occurred: can only concatenate list (not \"NoneType\") to list\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    graph.invoke({\"foo\" : None})\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d4930-ee8f-4ffc-b9e1-3c910b2e15f6",
   "metadata": {},
   "source": [
    "## Custom Reducers\n",
    "\n",
    "To address cases like this, [we can also define custom reducers](https://langchain-ai.github.io/langgraph/how-tos/subgraph/#custom-reducer-functions-to-manage-state). \n",
    "\n",
    "For example, lets define custom reducer logic to combine lists and handle cases where either or both of the inputs might be `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3314219d-29ff-4b78-b18e-fa9f7878a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_list(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Safely combine two lists, handling cases where either or both inputs might be None.\n",
    "\n",
    "    Args:\n",
    "        left (list | None): The first list to combine, or None.\n",
    "        right (list | None): The second list to combine, or None.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list containing all elements from both input lists.\n",
    "               If an input is None, it's treated as an empty list.\n",
    "    \"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    return left + right\n",
    "\n",
    "class DefaultState(TypedDict):\n",
    "    foo: Annotated[list[int], add]\n",
    "\n",
    "class CustomReducerState(TypedDict):\n",
    "    foo: Annotated[list[int], reduce_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdea26a-38d0-4faf-9bf6-cd52eb902635",
   "metadata": {},
   "source": [
    "In `node_1`, we append the value 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f270db-6eff-47c9-853b-dfb8108ff28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError occurred: can only concatenate list (not \"NoneType\") to list\n"
     ]
    }
   ],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [2]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(DefaultState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "try:\n",
    "    print(graph.invoke({\"foo\" : None}))\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21936b-62f1-4311-9ce5-2c7d08aa35bf",
   "metadata": {},
   "source": [
    "Now, try with our custom reducer. We can see that no error is thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867784bc-796c-4b1e-a4d3-2810395cf5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADqAGIDASIAAhEBAxEB/8QAHQABAAMAAwEBAQAAAAAAAAAAAAUGBwIECAMBCf/EAEUQAAEDBAADBAYGBgkDBQAAAAEAAgMEBQYRBxIhExQxQQgVIjJRlBZCYXF00yM2VFahshc1VWJydYGz0SRSkQklk5Wx/8QAGgEBAQADAQEAAAAAAAAAAAAAAAECAwUGBP/EADERAAIBAgEICgIDAQAAAAAAAAABAgMRMQQSIUFRcaHRBRQzYWKRkrHB8CNSEzLh8f/aAAwDAQACEQMRAD8A/qmiIgCLqXW5wWa3zVlSXCGIbIY0uc4k6DWtHVziSAAOpJAHioP6OVWTfp7/ACyx0ztmO0U8pZGxvl2zmncr/iN8g8AHa53bYwTWdJ2X3AqRM1N9ttFIWVFxpIHg6LZZ2tI/0JXx+lVl/tig+ZZ/yvlT4Xj9JGGQWK2wsAA5WUkYHToPJfX6K2X+x6D5Zn/Cz/D38BoH0qsv9sUHzLP+VyjyW0SvDWXWie4+DW1DCT/FcforZf7HoPlmf8LjJiNimYWSWW3PafFrqWMg/wAE/D38BoJVrg4Aggg9QR5r9VZdhEFtcZ8elNjqdl3ZQjdLKT5Ph8Nb82crv73ipKxXo3aOaKog7lcaV3Z1VKXcwY7yc12hzscOrXaGx0Ia4Oa3GUFbOg7riLbCUREWkgREQBERAVe56u2dWugfp1Pb6d9yew/WlJ7OE/aAO2Oj5hp8QCLQqw4dz4lMe/YbcLV2bDrpzQSkkb+JE+wPPlPwVnX0VcIpYW/7xuVmQt9K7hnXR5I205G271Vho6itqYqWkqHMcyEhryyQRlsgDnNG2F3vBRnB/wBLPEuJXCOqza4TPsotcMc14p+61MjKIyPc2NrXmIdtvl8Yw7r8FkvCKx5TZ+JFwxPBsezKw8L6yguXf7VmNvEFLbap/N2RoJiS57HyO2WgkAOLjs+7GYpf+Jtl9EmiwywYbmmNZTjMlLR3aoZbQ2eakdUSdu63OcSJpAwDq0dOfofNfOQ9HWr0muGd7wO+ZlRZTFPj1jc1tynFLOJaUuIDeeAx9qNk9PY69fgVQOJHpyYFi2LUN4x6pkySOou1PbXyCiq4YWMedySteYdS8rOoaw+1saK87XDh7lVXjHpDi3YnxCqaXJbJaZLU/KaaapuVe6GbkkDyA484JJEZ9oMAOgF6P9J3DbzX8B8TGP2GrutRjt1tFzktFvh5qh0NO4c7I4/NwB90fBAbliWV2zOMcob7Zp5Km11rO0gllgkgc5uyNlkjWub1B6EBR+Q6tOU2C5R6b3qV1sqfH22OY98f38r26HwEjvj17WD5V9N8Wob36outhFWHkW+90vdqyINe5v6SPZ5d8vMBvwcF1cxHe7njFC3ZkkuQqDoe6yKN7y4/Ac3I373BfRQ/vbVZ+xViWdERfOQIiIAiIgInIrM670sL6d7YbhSSipo5nglrJACNOA6lrmuc1wH1XHXXRSy5FBdZJKWVvc7rAP09DI722eXM3w54z5PHQ+HQggSyjb1jttyGKNlwpI6gxEuikO2yROI0Sx405h1020grdGUWs2eHt9+993kkirBwYsHLBkV9p2dNN74JdD75GuP/AJO1+fQmo/eq/f8AzQ/lLLMp/vwYstpaEWV8Kbfdcz4eWS9XHKbyK2shMkogkhDN8xHQdmfh8VbPoPM7o/J789vmO8Rt/i2MH+Kfx0/34MWW0mrteqKx03b1s4iYTysaGl75HeTWMaC57j5NaCT5BR1jt1RVXKa+XKHsKuaPsaamJ2aWDYdyuIJBkc4Bz9dOjGgu5OZ32tOIWuz1Rq4oXz1xBBrKyZ9RNo+ID3kloPT2W6HQdOgUyo5Rimoa9f378twREWggREQBERAEREAREQGe+j8QeDWLcpJHdTon/G77StCWe+j9v+hvFt633Y+7rXvu+HRaEgCIiAIiIAiIgCIiAIiIAiIgM89Hwa4M4qA4O/6U9WjofbctDWeej5r+hnFddR3U+I19dy0NAEREAREQBERAEX45wY0ucQ1oGySegCpRzC93YCostsoTbX9Yai4VL45Jm+TxG2M8rT4jZ2R4gLdTpSq3zeRbXLsipHr3MP2Cx/Nzflp69zD9gsfzc35a3dVntXmhYu6yz0keNVZwA4aS5jTYxJlNPTVUUNXTxVfdzBE/Y7Yu5H7Af2bda+vvfTrOevcw/YLH83N+WorLKO/5tjF1sF3tNiqbZc6aSkqIjVzdWPaQdfouhG9g+RAKdVntXmhYxz0EvSPq+NFgnx6HD32m145SNZLd3V4lEsz3ksjEYibr2eck76co6e109Xrz96PvCa7+jzw7gxWz01nrQJ5KmprpqiVslRK4+8QIzrTQ1oHwb9q0r17mH7BY/m5vy06rPavNCxd0VI9e5h+wWP5ub8tPXuYfsFj+bm/LTqs9q80LF3RUpmQ5XCeea1WmoY3qY6etka9w/u80et/AEgfaFaLPdqe+W6GtpS4wyb6PaWua4Etc1wPgQQQR5EFaqlGdNXeHc7ix3URFoIReUEtxm7kHRFHMQR/gKr2MgDG7UAAAKSLQH+AKw5V+rF4/BzfyFV7Gv1ctX4SL+QLo0exe/wCC6iSREWRAiKJyzK7Xg2N3G/3uq7labfCZ6mo7N8nZsHieVgLj9wBKgJZFxY8SMa9p21w2D9i5KgIojK8us2D2Se7364w2y2wkB8850OYnTWgDq5xJADQCSfAKXUAXV4aH/wBluA8hdq7QH4h67S6vDT+prj/m1d/vvVqdjLevkuotqIi5hCLyr9WLx+Dm/kKr2Nfq5avwkX8gVhyr9WLx+Dm/kKr2Nfq5avwkX8gXRo9i9/wXUSS8hcN7jkFq4d8D82ly/Irpdb/eqa1XKG43KSalnp5Wzt12J9kOb2bCJNc5IPM52169VQo+EmJ0GOY3YYLV2dpx2rjrrXT95lPd5o+bkdzF/M7XO7o4kdeo8FGrkPOEuSZIODU/GV+XXtuTsvzmNsQrT6tELbl3TuJpfdJMY9/Xacx3zKP4sUtx4o8HeN+W3XKL3TyWavuNoo7FQ1phooIKZ4YGzQjpK+Qbe5z9nT28utAr0c/gHgUmX/Sd2OxG7d89YbM8vd+9ftHd+fsu18+05ObfXe+q6eXejbw4zm7XS5XnHBUVV1YGV5hrainZVaGg6SOORrXOAA08jmGh1WLiwZFfqjPuKXFbN7NZp6qCixhtFS0kFHlUtldEZaZsveHsjpZe35nOIHOeUCPXLvZPonh/BkNLhNkhyyemqskjpI2XCejP6KWYDTnt6N8T18B4+Cgsz4E4NxAu0VzvljFRcI4BSmpp6qemfLCPCOQxPb2jP7r9jqV9brZc+grXRY5e8XttkiYyOlpK6x1FRLE1rANOkZWRtPUHWmDQ0OutnJJp3BnXpoYdZ7xweuF+raNtTdLTJStoZZHEinMlbTte5rd8vMWjl5tbAJAIBO99VSq8JkzXCZ7BnpoL6ypka6cW2CahheGSNkj03tnvBDmNJ9vrrw10VtVS03AXV4af1Ncf82rv9967S6vDT+prj/m1d/vvWVTsZb18l1FtREXMIReVfqxePwc38hVexr9XLV+Ei/kCuNRBHVQSQyt54pGljmnzBGiFQ4aW/wCM08NubZJr5T07GxQ1lHUQtc9gGm9o2V7NP0OuiQfHpvlHQydpwcL2d76Xb3MlpVidRQnra/fuZdfmqL89PW1+/cy6/NUX5635niXqXMWJtFCetr9+5l1+aovz09bX79zLr81RfnpmeJepcxYm0VTx3N6/K7JSXe14pdam31TOeGbt6RnMNkb06YEdQfEKR9bX79zLr81RfnpmeJepcxYm0UJ62v37mXX5qi/PT1tfv3MuvzVF+emZ4l6lzFibXV4af1Ncf82rv9966DK/Iqj2IsTqqeQ9GvraymbED8XGOR7gPuaT9hVnxmx/R60R0jpu8TF8k803LyiSWR5e8gbOhzOOhs6Ghs6Wqs1Gk43V21g09uwYIlURFzTEIiIAiIgCIiAz7gCNcHcXGtf9MemtfXd9g/8AxaCs99H5vLwaxYaI1THoRo++7yWhIAiIgCIiAIiIAiIgCIiAIiIDPPR8IPBnFdHY7qfLX13eS0NZ76P4cODmLcxcXd2Oy8aPvu8VoSAIiIAiIgCIiAIiIAiIgCisjyyx4dQx1t/vNvsdHJIIWVFyqmU8bpCCQwOeQC7TXHXjoH4JecqsuOlout4oLYXdWisqWRF33cxG1inpQWvB+PHBm+4scnsoufL3u2yPrYx2dXGCY/rdObbmE+QeVujRqzV4xbW5ls2WL0ac5xm+8M8etFryC1XC6U9E6SagpK2KWeJgkILnRtcXAbc0bP8A3D4rXl4b/wDTvwTGuD2B3LJclu9stuV32Tsu7VVTGyalpY3HlYQTtpe7biPgGL2Rbc6xu81Laagv9srKl2tQwVkb3nfh7IO1XQqxV3B+TFmTiIi0ECIiAIiIAiIgCyPiTxMqJKyosljqXU4gcYqyui98P844z5EfWd5HoNEEjQ8yvT8cxK83SMB0tHSSzRtPgXtaS0f+dLzbSQGmpo43PMjwPbkcdl7vEuJ+JOyfvXpOh8jhWk61RXSwXf8A4XBXPyKjhhlfK2MGZ55nzO9qR5+LnHq4/aSvsqnnvEu18Phb4quCuuVyuL3R0VrtcHb1VQWjby1mwNNHUkkAKtVHpFYzS45Bdn0d4533Vtmltnc9VtPVOa5zWPiLt9Q3Q5ebZI1569bKvSg3GUtKMMTUV8qmkgrYzHUQxzxnxbKwOB/0Ko9g40WC8UeQzVkVfj01gY2W40l5p+xmhjc0ua/lBcHBwB1ok/Z1G6JScbarNeMHDygtVDfbLY66OvlmbdKIQR3BrYOaJ8Z2S5oIJ8veaSOoWEsqpxs073aXG3uD0/hHESswqZkNbUT1tgOg+OQmWSkG/fjJ24sA8Wdeg9jRHK7fIZo6iJksT2yRPaHNew7DgeoIPmF5cWx8Dbo+swuShe4u9VVclEwk+EemyRt+5rJWtH2NC890zkcFHrEFZ308zJO6NDREXkgEREAREQEDnlolv2FXy3045qmoo5WQj4ycp5f46XnKkqWVlLDOz3JWB4/1G16rWH8SOHs2O1tVeLbC+e0VD3T1EMTS51I89XOAHUxk7J17pJ+r7vp+hcqhTcqE3a+lb9nIYqx5f49cLLnluTYxkdutAyWO2Mmp6qzi4uoJJWPA0+OZrm8pBB2CevRQbuDdaLBic9pw04/cW5fQ3W6Ubrwa1zKaEyDtXSyPPMQ1w9lmz16Ar0JDNHURNkie2SNw217DsEfYVyXo5ZHTlOU3i93K+raYmFZ5wevma5RxNDIm0lDfLLSU1DWPlbyvnidzcrmglzRsAEkeB6bXzsdm4gZHxM4cXS/4dFYqLHaetp6mphuUM7ZHSU4Y1wY08zWktGgOYjfXWtneU8EeSQzs5N431adOds2gLX+BFFJDiNZWv3yXC4SzRb/7GtbCP9CYiR9+/NZth2J1ef1fZUbnw2tjtVNyZ7rQD7UcR+tIeo2Nhni7rprvRFvoKe1UFNRUkTYKWmjbDDEzwYxoAa0fYAAFxumsqgodXi9N9PcZLQjsIiLxwCIiAIiIAiIgKneuFWKX6pfU1VniZUyHmkmpJH0z5D8XOic0uP2najjwOxEknutf1+F1qvzFfUX1xyzKYLNjUklvZbsoP9BuI/stf/8AbVf5q7FLwZw6mlEjrP3sjXs11TNUsP3ske5v8FdkWTy3KmrOrLzYuzhFEyniZFExscbGhrWMGg0DwAHkFzRF8RAiIgCIiA//2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "{'foo': [2]}\n"
     ]
    }
   ],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(CustomReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "try:\n",
    "    print(graph.invoke({\"foo\" : None}))\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebc65e-c185-4981-a6e7-20fe37d2f8fe",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "In module 1, we showed how to use a built-in reducer, `add_messages`, to handle messages in state.\n",
    "\n",
    "We also showed that [`MessagesState` is a useful shortcut if you want to work with messages](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate). \n",
    "\n",
    "* `MessagesState` has a built-in `messages` key \n",
    "* It also has a built-in `add_messages` reducer for this key\n",
    "\n",
    "These two are equivalent. \n",
    "\n",
    "We'll use the `MessagesState` class via `from langgraph.graph import MessagesState` for brevity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "901e69e5-c4cb-4d58-82fb-3b7d968758e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Define a custom TypedDict that includes a list of messages with add_messages reducer\n",
    "class CustomMessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    added_key_1: str\n",
    "    added_key_2: str\n",
    "    # etc\n",
    "\n",
    "# Use MessagesState, which includes the messages key with add_messages reducer\n",
    "class ExtendedMessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    added_key_1: str\n",
    "    added_key_2: str\n",
    "    # etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287805e4-722a-4428-b040-2892b29de870",
   "metadata": {},
   "source": [
    "Let's talk a bit more about usage of the `add_messages` reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8f61350-4fe0-4a2b-bb24-9305afb3c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='7754c954-efc1-4629-867b-255ddde188a6'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='3568d9e2-1763-4bbe-b53b-c0ea4224d175'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='c205c328-c1c5-4d47-890f-1376e43049f4')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc492370-0502-43e6-87cc-181c60b3dbdb",
   "metadata": {},
   "source": [
    "So we can see that `add_messages` allows us to append messages to the `messages` key in our state.\n",
    "\n",
    "### Re-writing\n",
    "\n",
    "Let's show some useful tricks when working with the `add_messages` reducer.\n",
    "\n",
    "If we pass a message with the same ID as an existing one in our `messages` list, it will get overwritten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f6f82fd-a5a8-4e98-80f6-bb058f2acc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='1'),\n",
       " HumanMessage(content=\"I'm looking for information on whales, specifically\", additional_kwargs={}, response_metadata={}, name='Lance', id='2')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\", id=\"1\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\", id=\"2\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = HumanMessage(content=\"I'm looking for information on whales, specifically\", name=\"Lance\", id=\"2\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e7788-7054-4752-99fe-27ebb901f263",
   "metadata": {},
   "source": [
    "### Removal\n",
    "\n",
    "`add_messages` also [enables message removal](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/). \n",
    "\n",
    "For this, we simply use [RemoveMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html) from `langchain_core`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67ac97e5-efe2-40bc-9fe3-fd4f50922b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='1'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='2')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "# Message list\n",
    "messages = [AIMessage(\"Hi.\", name=\"Bot\", id=\"1\")]\n",
    "messages.append(HumanMessage(\"Hi.\", name=\"Lance\", id=\"2\"))\n",
    "messages.append(AIMessage(\"So you said you were researching ocean mammals?\", name=\"Bot\", id=\"3\"))\n",
    "messages.append(HumanMessage(\"Yes, I know about whales. But what others should I learn about?\", name=\"Lance\", id=\"4\"))\n",
    "\n",
    "# Isolate messages to delete\n",
    "delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]\n",
    "print(delete_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d250578-3ec0-452e-91c0-072d785d96db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='So you said you were researching ocean mammals?', additional_kwargs={}, response_metadata={}, name='Bot', id='3'),\n",
       " HumanMessage(content='Yes, I know about whales. But what others should I learn about?', additional_kwargs={}, response_metadata={}, name='Lance', id='4')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_messages(messages , delete_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db095c5-6d9a-4e62-a097-0403797511f6",
   "metadata": {},
   "source": [
    "We can see that mesage IDs 1 and 2, as noted in `delete_messages` are removed by the reducer.\n",
    "\n",
    "We'll see this put into practice a bit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0347d-cbf0-4164-9cf6-39c4e040a313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
